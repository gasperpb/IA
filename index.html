<!DOCTYPE html>
<html lang="pt_br">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ia</title>
</head>

<body>
    <div>
        <p>








            INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNOLOGIA DA PARAÍBA CAMPUS CAMPINA GRANDE Curso: Tecnologia em Telemática Disciplina: Introdução à Telemática Professora: Iana Daya C. F. Passos IA Compreensão sobre o assunto e aplicação nos meios computacionais.
            Equipe: Achilles Robson, Cefras José, Wagner Gabriel São José do Belmonte, 02/12/2020 Introdução Objetivo: Estudar a aplicação da tecnologia e de como ela se encaixa na realidade das novas inovações nos meios computacionais, apresentar situações
            em que executar funções que caso um ser humano fosse executar, seriam consideradas inteligentes. E despertar curiosidade de estudar e poder inová-lo também para os estudantes. Conceito: Inteligência artificial é um campo da ciência, cujo propósito
            é estudar, desenvolver e empregar máquinas para realizarem atividades humanas de maneira autônoma. Por ações racionais, diante de determinadas situações que simulem a inteligência humana. História Surgimento: O conceito de inteligência artificial
            não é contemporâneo. Aristóteles, professor de Alexandre, o Grande, almejava substituir a mão-de-obra escrava por objetos autônomos, sendo essa a primeira idealização de Inteligência Artificial relatada, uma ideia que seria explorada muito
            tempo depois pela ciência da computação. O desenvolvimento dessa ideia se deu de forma plena no Século XX, com enfoque nos anos 50, com pensadores como Herbert Simon e John McCarthy. Os primeiros anos da IA foram repletos de sucessos – mas
            de uma forma limitada. Considerando-se os primeiros computadores, as ferramentas de programação da época e o fato de que apenas alguns anos antes os computadores eram vistos como objetos capazes de efetuar operações aritméticas e nada mais,
            causava surpresa o fato de um computador realizar qualquer atividade remotamente inteligente. O sucesso inicial prosseguiu com o General Problem Solver (Solucionador de problemas gerais) ou GPS, desenvolvido por Newell e Simon. Esse programa
            foi projetado para imitar protocolos humanos de resolução de problemas. Dentro da classe limitada de quebra-cabeças com a qual podia lidar, verificou-se que a ordem em que os seres humanos abordavam os mesmos problemas. Desse modo, o GPS talvez
            tenha sido o primeiro programa a incorporar a abordagem de “pensar de forma humana”. Desde o início os fundamentos da inteligência artificial tiveram o suporte de várias disciplinas que contribuíram com ideias, pontos de vista e técnicas para
            a IA. Os filósofos (desde 400 a.C.) tornaram a IA concebível, considerando as ideias de que a mente é, em alguns aspectos, semelhante a uma máquina, de que ela opera sobre o conhecimento codificado em alguma linguagem interna e que o pensamento
            pode ser usado para escolher as ações que deverão ser executadas. Por sua vez, os matemáticos forneceram as ferramentas para manipular declarações de certeza lógica, bem como declarações incertas e probabilísticas. Eles também definiram a
            base para a compreensão da computação e do raciocínio sobre algoritmos. Os economistas formalizaram o problema de tomar decisões que maximizam o resultado esperado para o tomador de decisões. Os psicólogos adotaram a ideia de que os seres
            humanos e os animais podem ser considerados máquinas de processamento de informações. Os linguistas mostraram que o uso da linguagem se ajusta a esse modelo. Os engenheiros de computação fornecem os artefatos que tornam possíveis as aplicações
            de IA. Os programas de IA tendem a ser extensos e não poderiam funcionar sem os grandes avanços em velocidade e memória que a indústria de informática tem proporcionado. Atualmente, a IA abrange uma enorme variedade de subcampos. Dentre esses
            subcampos está o estudo de modelos conexionistas ou redes neurais. Uma rede neural pode ser vista como um modelo matemático simplificado do funcionamento do cérebro humano. Este consiste de um número muito grande de unidades elementares de
            processamento, ou neurônios, que recebem e enviam estímulos elétricos uns aos outros, formando uma rede altamente interconectada. A utilização da IA permite obter não somente ganhos significativos de performance, mas também possibilita o desenvolvimento
            de aplicações inovadoras, capazes de expandir de forma extraordinária nossos sentidos e habilidades intelectuais. Cada vez mais presente, a inteligência artificial simula o pensamento humano e se alastra por nosso cotidiano. Em maio de 2017
            no Brasil, foi criada a ABRIA (Associação Brasileira de Inteligência Artificial) com o objetivo de mapear iniciativas brasileiras no setor de inteligência artificial, englobando os esforços entre as empresas nacionais e formação de mão de
            obra especializada. Esse passo reforça que, atualmente, a inteligência artificial é impactante no setor econômico. Características: Machine learning automatiza a construção de modelos analíticos. Ele usa métodos de redes neurais, estatística,
            pesquisas de operações e física para encontrar insights escondidos em dados, sem ser especificamente programado para olhar um determinado lugar ou chegar a uma determinada conclusão. Uma rede neural é um tipo de machine learning composta de
            unidades interconectadas (como neurônios), que processam informações ao responder a entradas externas, retransmitindo-as entre as unidades. O processo requer passagens múltiplas nos dados para encontrar conexões e extrair significados de dados
            não-definidos. Deep learning utiliza grandes redes neurais com muitas camadas de unidades de processamento, aproveitando-se de avanços no poder computacional e em técnicas de treinamento aprimoradas para aprender padrões complexos em grandes
            quantidades de dados. Aplicações comuns incluem reconhecimento de imagem e fala. Computação cognitiva é um subcampo de IA que almeja uma interação natural e humana com máquinas. Utilizando IA e computação cognitiva, o objetivo final é que
            a máquina simule processos humanos através da capacidade de interpretar imagens e fala – e, então, falar coerentemente em resposta. Visão computacional depende do reconhecimento de padrões e de deep learning para entender o que há em uma imagem
            ou vídeo. Quando máquinas podem processar, analisar e entender imagens, eles podem capturar imagens ou vídeos em tempo real e interpretar o que há ao redor delas. Processamento de linguagem natural (PLN) é a capacidade que os computadores
            tem de analisar, entender e gerar linguagem humana, incluindo fala. O próximo estágio do PLN é a interação de linguagem natural, que permite que seres humanos se comuniquem com computadores utilizando linguagem normal, de uso diário, para
            realizar tarefas. E dentre outras as tecnologias possibilitam e oferecem suporte à IA: Unidades de processamento gráfico são essenciais para a IA, porque fornecem o poder computacional pesado que é necessário para o processamento contínuo.
            Treinar redes neurais requer big data e poder computacional. A Internet das Coisas gera grandes quantidades de dados a partir de aparelhos conectados, sendo que a maioria deles não são analisados. Automatizar modelos com IA permitirão um maior
            uso deles. Algoritmos avançados estão sendo desenvolvidos e combinados em novas maneiras para analisar mais dados, mais rapidamente e em múltiplos níveis. Esse processamento inteligente é essencial para identificar e prever eventos raros,
            entendendo sistemas complexos e otimizando cenários únicos. APIs são pacotes portáteis de códigos que possibilitam a adição de funcionalidades de IA a produtos existentes e pacotes de software. Eles podem adicionar capacidades de reconhecimento
            de imagens a sistemas de segurança doméstica e capacidades de perguntas e respostas que descrevem dados, criam legendas e títulos ou chamam atenção para padrões interessantes e insights nos dados. Principais Aplicações Vantagens e desvantagens:
            • Redução de erros: Uma vez que são máquinas, a inteligência artificial é mais resistente e tem maior capacidade de suportar ambientes hostis, reduzindo as chances de falharem em seus propósitos, tendo a possibilidade de alcançar um maior
            grau de precisão. • Exploração: Devido à programação dos robôs, eles podem realizar um trabalho mais laborioso e duro com maior responsabilidade. Assim, são capazes de ser utilizadas também em processos de exploração de minérios e de outros
            combustíveis, no fundo do oceano e, portanto, superar as limitações humanas. • Aplicações diárias: Inteligência Artificial é amplamente empregada por instituições financeiras e instituições bancárias para organizar e gerenciar dados. A sua
            utilização está presente em vários mecanismos do nosso cotidiano como o GPS (global positioning system), a correção nos erros de digitação na ortografia, entre outros. • Sem pausas: As máquinas, ao contrário dos seres humanos, não precisam
            de intervalos frequentes. Elas conseguem exercer vários horas de trabalho sem ficarem cansadas, distraídas ou entendiadas, apenas pela sua programação. • Alto custo: o custo de produção das máquinas de IA são demasiados, o que se deve a complexidade
            e dificuldade de manutenção. O processo de recuperação de códigos perdidos, por exemplo, requer muito tempo e recursos. • Falta de criatividade: A inteligência artificial não é desenvolvida ao ponto de atuar como o cérebro humano, de forma
            criativa. Ademais, o cérebro humano ainda não é suficientemente compreendido para que um dia possa ser simulado fielmente em uma forma artificial. Portanto, a ideia de replicar funções do cérebro humano é intangível. • Causa o desemprego:
            Como são capazes de executar tarefas antes exclusivas aos humanos de maneira mais otimizada e eficiente, os mecanismos de inteligência artificial tendem a substituir a atividade humana em larga escala. O trabalho de uma máquina que possui
            inteligência artificial é, muitas vezes, mais viável que o trabalho humano, logo, a projeção de um crescimento no desemprego em função disso é coerente. Curiosidades (se existirem): Os principais pesquisadores para desenvolvimento e aperfeiçoamento
            da IA são eles: Alan Turing (1912-1954): Criou seu famoso teste, o “Teste de Turing”, usado até hoje para descobrir o nível de inteligência de um programa de inteligência artificial. John McCarthy (1927-2011): McCarthy foi considerado um dos
            primeiros homens a trabalhar no desenvolvimento da inteligência artificial e sempre disse que ela deveria interagir com o homem. Já a programação LISP, uma das maiores conquistas de McCarthy, surgiu em 1958 e serviu para facilitar o desenvolvimento
            da inteligência artificial. A linguagem é das mais antigas ainda em uso e foi usada pela primeira vez ao colocar um computador para jogar xadrez contra um adversário humano. Marvin Minsky (1927-2016): O cientista explorou a forma de dotar
            as máquinas de percepção e inteligência semelhantes à humana, criou mãos robóticas com capacidade para manipular objetos, desenvolveu novos marcos de programação e escreveu sobre assuntos filosóficos relacionados com a inteligência artificial.
            Raj Reddy (1937): Informático indiano naturalizado estadunidense, foi o primeiro asiático a vencer o Prêmio Turing. Entre suas contribuições para a IA estão a criação do Instituto de Robótica da CMU e demonstrações de diversos sistemas que
            usam alguma forma de IA. Terry Winograd (1946): Para Terry, não restam dúvidas de que a tecnologia da informática, mais precisamente a área de inteligência artificial, transformará as sociedades, introduzindo modificações socioeconômicas irreversíveis.
            Esse especialista procura saber se os seres-humanos seriam capazes de construir máquinas que poderiam compreende-los, resolver seus problemas e dirigir suas vidas, além de buscar respostas sobre o que aconteceria se, algum dia, essas máquinas
            se tornassem mais inteligentes do que os próprios humanos que as criaram. Douglas Lenat (1950): Executivo do Cycorp e foi também um pesquisador proeminente em inteligência artificial, recebendo o prêmio bianual IJCAI Computers and Thought
            em 1976 pela criação do programa de aprendizado de máquinas. Ele também trabalhou em simulações militares e em numerosos projetos para organizações governamentais, militares, científicas e de inteligência dos EUA. A missão de Lenat, no longo
            ciclo do projeto Cyc, iniciado em 1984, era de construir a base de uma inteligência artificial geral ao representar manualmente o conhecimento como axiomas lógicos contextualizados na linguagem formal com base em extensões ao cálculo de predicados
            de primeira ordem e em seguida, usar esse enorme motor de inferência de ontologia e a base de conhecimento contextualizada como um viés indutivo para automatizar e acelerar cada vez mais a educação contínua do próprio Cyc, E dentre outras
            as tecnologias possibilitam e oferecem suporte à IA: Unidades de processamento gráfico são essenciais para a IA, porque fornecem o poder computacional pesado que é necessário para o processamento contínuo. Treinar redes neurais requer big
            data e poder computacional. A Internet das Coisas gera grandes quantidades de dados a partir de aparelhos conectados, sendo que a maioria deles não são analisados. Automatizar modelos com IA permitirão um maior uso deles. Algoritmos avançados
            estão sendo desenvolvidos e combinados em novas maneiras para analisar mais dados, mais rapidamente e em múltiplos níveis. Esse processamento inteligente é essencial para identificar e prever eventos raros, entendendo sistemas complexos e
            otimizando cenários únicos. APIs são pacotes portáteis de códigos que possibilitam a adição de funcionalidades de IA a produtos existentes e pacotes de software. Eles podem adicionar capacidades de reconhecimento de imagens a sistemas de segurança
            doméstica e capacidades de perguntas e respostas que descrevem dados, criam legendas e títulos ou chamam atenção para padrões interessantes e insights nos dados. Perspectivas Futuras “Todos os aspectos das nossas vidas serão transformados,
            e isso pode ser o maior evento na história da nossa civilização”. Essa frase foi dita pelo brilhante físico e cientista Stephen Hawking. Ele se referia à Inteligência Artificial (IA) – um termo que está na moda, mas que já existe há cerca
            de duas décadas. Desde o início do século 21, o fundador e CEO do SAS, Jim Goodnight, já utiliza a Inteligência Artificial em tecnologias como análise preditiva, inteligência do consumidor e soluções antifraude, pois todas elas já tinham esse
            componente embutido no código fonte. Mas isso ficava escondido na ‘casa de máquina’. Se há algumas décadas as pessoas só imaginavam máquinas capazes de aprender com os seres humanos, hoje isso é uma realidade, principalmente, com os assistentes
            virtuais. E como previsto no livro Eu Robô, escrito em 1950 por Isaac Asimov, os robôs já começaram a substituir os humanos em diversas funções, já que eles, ou as máquinas, conseguem guardar, cruzar e analisar dados em uma velocidade infinitamente
            maior do que a dos humanos. Atualmente essa tecnologia que ‘aprende’ já está ajudando também alguns departamentos de polícia pelo mundo na identificação de crimes. É o caso do estado da Carolina do Norte (EUA), que utiliza o SAS Visual Investigator
            para descobrir pistas e comportamentos suspeitos que podem representar perigo para crianças. Considerações Finais Referências Bibliográficas https://www.totvs.com/blog/inovacoes/o-que-e-inteligencia-artificial/ https://tecnoblog.net/263808/o-que-e-inteligencia-artificial/
            https://www.sas.com/pt_br/insights/analytics/inteligencia-artificial.html#world https://canaltech.com.br/inteligencia-artificial/inteligencia-artificial-o-futuro-e-agora-100050/ https://pt.wikipedia.org/wiki/Inteligência_artificial#História


        </p>
    </div>

</body>

</html>